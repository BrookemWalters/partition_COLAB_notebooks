{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOsB3hs/xT3mlBMuuwgLcB0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/partition_COLAB_notebooks/blob/main/partition_numba_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partition with NUMBA/CUDA\n",
        "This python program is based on NUMBA/CUDA.\n",
        "It solves the partition problem.\n",
        "\n",
        "Make sure that COLAB has been set up to use a GPU.\n",
        "In the main menu select the option:\n",
        " Runtime\n",
        "In the pull-down menu select:\n",
        " Change runtime type\n",
        "Select:\n",
        " T4 GPU"
      ],
      "metadata": {
        "id": "TvlzT8w3e-P6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU cards are dedicated computers with their own memory and their own processors.\n",
        "\n",
        "When programming a GPU,"
      ],
      "metadata": {
        "id": "55bVlOe8hulr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KPmcXCre9UJ",
        "outputId": "7c091e46-b9cf-4c57-b9af-1d3b41397a7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing partition_numba_cuda.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile partition_numba_cuda.py\n",
        "#\n",
        "# Program that solves the partition problem in python\n",
        "# Parallel version with numba\n",
        "#\n",
        "import sys\n",
        "import numpy as np\n",
        "#import numba\n",
        "from numba import cuda\n",
        "from numba.cuda.cudadrv.devicearray import DeviceNDArray\n",
        "import time\n",
        "\n",
        "#\n",
        "# This is the kernel, the code that is executed in each processor\n",
        "# in the GPU\n",
        "#\n",
        "@cuda.jit\n",
        "def evaluatePartition(array:DeviceNDArray,result:DeviceNDArray,n:np.dtype=np.int64):\n",
        "   value = cuda.grid(1)\n",
        "   sum0s = 0\n",
        "   sum1s = 0\n",
        "   mask = 1\n",
        "   for i in range(0,n):\n",
        "    if ((mask & value) != 0):\n",
        "      sum1s = sum1s + array[i]\n",
        "    else:\n",
        "      sum0s = sum0s + array[i]\n",
        "    mask = mask * 2\n",
        "   if (sum0s == sum1s):\n",
        "     # print(\"Evaluate partition \",value,\" returns \",value)\n",
        "     result[value] = value\n",
        "   else:\n",
        "    # print(\"Evaluate partition \",value,\" returns \",0)\n",
        "    result[value] = 0\n",
        "\n",
        "def printResults(value, n, array):\n",
        "  print(\"Solution:\\n\")\n",
        "  print(\"First partition: \")\n",
        "  mask = 1\n",
        "  sum = 0\n",
        "  for i in range(0,n):\n",
        "\n",
        "    if ((mask & value) != 0):\n",
        "      print(array[i],\" \")\n",
        "      sum = sum + array[i]\n",
        "    mask = mask * 2\n",
        "  print(\" sum: \",sum)\n",
        "  print(\"Second partition: \")\n",
        "  mask = 1\n",
        "  sum = 0\n",
        "  for i in range(0,n):\n",
        "    if ((mask & value) == 0):\n",
        "      print(array[i],\" \")\n",
        "      sum = sum + array[i]\n",
        "\n",
        "    mask = mask * 2\n",
        "\n",
        "  print(\" sum: \\n\",sum)\n",
        "\n",
        "def parallelFor(n,array,nPartitions):\n",
        "  solutionFound = 0\n",
        "  solution = -1\n",
        "  result = np.zeros(nPartitions,dtype=np.int64)\n",
        "  arrayGPU = cuda.to_device(array)\n",
        "  resultGPU = cuda.to_device(result)\n",
        "  evaluatePartition.forall(nPartitions)( arrayGPU,resultGPU, n)\n",
        "  # Copy the result array back to the CPU\n",
        "  resultGPU.copy_to_host(result)\n",
        "\n",
        "  # print(\"At the end array contains: \",result)\n",
        "  solutionFound = np.max(result)\n",
        "  solution = solutionFound\n",
        "\n",
        "\n",
        "  if (solutionFound):\n",
        "    printResults(solution, n, array)\n",
        "  else:\n",
        "    print(\"No solution was found.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  start = time.time()\n",
        "  # Read the problem\n",
        "  n = int(input())\n",
        "  valuesString = input()\n",
        "  values = valuesString.split()\n",
        "  for i in range(len(values)):\n",
        "    values[i] = int(values[i])\n",
        "# Print the instance of the problem\n",
        "  print(\"Problem size: \",n)\n",
        "  print(\"Problem instance: \",values)\n",
        "  nPartitions = 2 ** n\n",
        "  np_array = np.array(values)\n",
        "  parallelFor(n,np_array,nPartitions)\n",
        "  end = time.time()\n",
        "  elapsed = end - start\n",
        "  print(\"The program took: \",elapsed,\" seconds.\")\n",
        "  parallelFor(n,np_array,nPartitions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile instanceNoSolution24.Text\n",
        "24\n",
        "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1000000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX2kQ_uvfrgh",
        "outputId": "0ad6bd6c-d36c-45a7-d884-af5cf1fdc37d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing instanceNoSolution24.Text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python partition_numba_cuda.py < instanceNoSolution24.Text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuDIsNWEgQAy",
        "outputId": "1744ac94-0e4b-4a58-b0c3-180a64414445"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem size:  24\n",
            "Problem instance:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 1000000]\n",
            "No solution was found.\n",
            "The program took:  1.2094764709472656  seconds.\n",
            "No solution was found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep 1 instanceNoSolution24.Text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_0U26D_jKcU",
        "outputId": "4ba2da10-f415-4d05-b859-73546e19c921"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!awk ' {print $0}' instanceNoSolution24.Text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4e1donNjVtR",
        "outputId": "ca57ea87-80b8-4d0b-f6cb-6cec27bfb96d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 1000000\n"
          ]
        }
      ]
    }
  ]
}